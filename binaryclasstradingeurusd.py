# -*- coding: utf-8 -*-
"""binaryclasstradingeurusd.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kk9I6vA0QZJrs_hdXVU2R-vhYG21SAMS
"""

# Imports
import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import classification_report, confusion_matrix
import lightgbm as lgb
import warnings
warnings.filterwarnings("ignore")

def rsi(series, window=14):
    delta = series.diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(window).mean()
    avg_loss = loss.rolling(window).mean()
    rs = avg_gain / avg_loss
    return 100 - (100 / (1 + rs))

def macd(series, span_fast=12, span_slow=26, span_signal=9):
    ema_fast = series.ewm(span=span_fast, adjust=False).mean()
    ema_slow = series.ewm(span=span_slow, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    signal_line = macd_line.ewm(span=span_signal, adjust=False).mean()
    return macd_line, signal_line

def atr(high, low, close, window=14):
    high_low = high - low
    high_close = (high - close.shift()).abs()
    low_close = (low - close.shift()).abs()
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    return tr.rolling(window).mean()

def stochastic_k(high, low, close, k_window=14):
    lowest_low = low.rolling(k_window).min()
    highest_high = high.rolling(k_window).max()
    return 100 * (close - lowest_low) / (highest_high - lowest_low)

from google.colab import files
uploaded = files.upload()  # choose 'week1_final_dataset.csv' from your downloads

import pandas as pd

df = pd.read_csv("week1_final_dataset.csv", parse_dates=True)
print("Dataset loaded. Shape:", df.shape)
df.head()

# -------------------------
# WEEK-2 FEATURE ENGINEERING + LABEL CREATION
# -------------------------

# ML parameters
LOOKAHEAD = 10
UP_TH = 0.01
DOWN_TH = -0.01

# --- 1) Price-based features ---
df['ret'] = df['Close'].pct_change()          # simple percent change
df['logret'] = np.log(df['Close']).diff()     # log return

# --- 2) Moving averages ---
df['sma_10'] = df['Close'].rolling(10).mean()
df['sma_50'] = df['Close'].rolling(50).mean()
df['ema_12'] = df['Close'].ewm(span=12, adjust=False).mean()

# --- 3) Technical indicators ---
df['rsi_14'] = rsi(df['Close'], 14)
df['macd'], df['macd_signal'] = macd(df['Close'])
df['stoch_k'] = stochastic_k(df['High'], df['Low'], df['Close'], 14)
df['atr_14'] = atr(df['High'], df['Low'], df['Close'], 14)

# --- 4) Lagged returns ---
for lag in [1,2,3,5,10]:
    df[f'ret_lag_{lag}'] = df['ret'].shift(lag)

# --- 5) Include structural features from Week-1 ---
possible_struct = ['Swing_High', 'Swing_Low', 'Support_Level', 'Resistance_Level',
                   'Supply_Zone_Width', 'Demand_Zone_Width', 'Nearest_Fib_Dist']
struct_cols = [c for c in possible_struct if c in df.columns]

print("Using structural columns:", struct_cols)

# --- 6) Label creation (Buy/Sell/Hold) ---
df['fwd_close'] = df['Close'].shift(-LOOKAHEAD)
df['fwd_ret'] = (df['fwd_close'] - df['Close']) / df['Close']

def label_from_ret(x):
    if x >= UP_TH: return 1      # Buy
    elif x <= DOWN_TH: return -1 # Sell
    else: return 0               # Hold

df['label'] = df['fwd_ret'].apply(lambda x: label_from_ret(x) if pd.notnull(x) else np.nan)

# --- 7) Prepare dataset for modeling ---
feature_cols = ['ret','logret','sma_10','sma_50','ema_12','rsi_14',
                'macd','macd_signal','stoch_k','atr_14'] + \
               [f'ret_lag_{lag}' for lag in [1,2,3,5,10]] + struct_cols

df_model = df[feature_cols + ['label']].dropna()
print("Label distribution:\n", df_model['label'].value_counts(normalize=True))
print("Prepared dataset shape:", df_model.shape)

# Use only rows with non-NaN labels
df_model = df[feature_cols + ['label']].dropna()

X = df_model.drop(['label'], axis=1)  # remove label
y = df_model['label']                  # target

print("Filtered dataset shape:", X.shape)
print("Missing labels:", y.isnull().sum())  # should be 0

from sklearn.model_selection import train_test_split

# Features: drop columns we don't want the model to see
X = df.drop(['label', 'Date'], axis=1)
y = df['label']

# Train/test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, shuffle=False  # shuffle=False for time series
)

print("Training set shape:", X_train.shape)
print("Test set shape:", X_test.shape)

# Drop rows with missing values
X_train = X_train.dropna()
y_train = y_train.loc[X_train.index]

X_test = X_test.dropna()
y_test = y_test.loc[X_test.index]

# Verify
print("Cleaned Training set shape:", X_train.shape)
print("Cleaned Test set shape:", X_test.shape)
print("Any missing in X_train now?", X_train.isnull().sum().sum())
print("Any missing in X_test now?", X_test.isnull().sum().sum())

# Check for missing values
print("Missing values in X_train:", X_train.isnull().sum().sum())
print("Missing values in X_test:", X_test.isnull().sum().sum())

from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# Set up the model with balanced classes
model = lgb.LGBMClassifier(
    objective='multiclass',
    num_class=3,
    random_state=42,
    class_weight='balanced'  # this balances the classes automatically
)

model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate
from sklearn.metrics import classification_report, confusion_matrix
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import joblib
joblib.dump(model, 'lgbm_model.pkl')

import matplotlib.pyplot as plt

lgb.plot_importance(model, max_num_features=20, importance_type='gain')
plt.show()

import lightgbm as lgb
import matplotlib.pyplot as plt

# Plot top 20 features by gain
lgb.plot_importance(model, max_num_features=20, importance_type='gain', figsize=(10,6))
plt.title("Top 20 Feature Importances (by Gain)")
plt.show()

importance = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': model.feature_importances_
}).sort_values(by='Importance', ascending=False)

print(importance.head(20))
